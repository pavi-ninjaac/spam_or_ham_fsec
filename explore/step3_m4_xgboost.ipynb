{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import optuna\n",
    "\n",
    "from xgboost import  XGBClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report, accuracy_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train  (3417, 1000)\n",
      "X test (375, 1000)\n",
      "Y_Train (3417, 1)\n",
      "Y_test (375, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = pd.read_csv(\"data/x_train.csv\", header=None)\n",
    "X_test = pd.read_csv(\"data/x_text.csv\", header=None)\n",
    "y_train = pd.read_csv(\"data/y_train.csv\", header=None)\n",
    "y_test = pd.read_csv(\"data/y_test.csv\", header=None)\n",
    "\n",
    "\n",
    "\n",
    "print(\"X train \",X_train.shape)\n",
    "print(\"X test\",X_test.shape)\n",
    "print(\"Y_Train\", y_train.shape)\n",
    "print(\"Y_test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace 1 with 0 and -1 with 1.\n",
    "\n",
    "# because XGBoost excepts: ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1], got [-1  1]\n",
    "y_train.replace(1, 0, inplace=True)\n",
    "y_train.replace(-1, 1, inplace=True)\n",
    "\n",
    "\n",
    "y_test.replace(1, 0, inplace=True)\n",
    "y_test.replace(-1, 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 22:54:02,949] A new study created in memory with name: no-name-f30d9da2-990c-44cc-b039-a6f6ef7e7c1f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pavithra/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:54:04] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-30 22:56:07,629] Trial 0 finished with value: 0.046511627906976744 and parameters: {'max_depth': 9, 'learning_rate': 0.28400861278242023, 'n_estimators': 150, 'subsample': 0.7829637164723547, 'gamma': 0.6441736721396305}. Best is trial 0 with value: 0.046511627906976744.\n",
      "/home/pavithra/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:56:09] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-30 22:57:58,117] Trial 1 finished with value: 0.078125 and parameters: {'max_depth': 7, 'learning_rate': 0.2587048337731825, 'n_estimators': 145, 'subsample': 0.8492330507799103, 'gamma': 0.44168416852096093}. Best is trial 1 with value: 0.078125.\n",
      "/home/pavithra/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:57:59] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-30 23:01:18,216] Trial 2 finished with value: 0.08163265306122448 and parameters: {'max_depth': 5, 'learning_rate': 0.07347185444552125, 'n_estimators': 140, 'subsample': 0.6478069602051036, 'gamma': 0.1913956509419259}. Best is trial 2 with value: 0.08163265306122448.\n",
      "/home/pavithra/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [23:01:19] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-30 23:02:46,560] Trial 3 finished with value: 0.0625 and parameters: {'max_depth': 8, 'learning_rate': 0.11882839922001913, 'n_estimators': 71, 'subsample': 0.6023809029172607, 'gamma': 0.16238736142435806}. Best is trial 2 with value: 0.08163265306122448.\n",
      "/home/pavithra/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [23:02:47] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-30 23:05:20,037] Trial 4 finished with value: 0.08196721311475409 and parameters: {'max_depth': 6, 'learning_rate': 0.0664130979103427, 'n_estimators': 157, 'subsample': 0.8797675533448208, 'gamma': 0.2901363155601894}. Best is trial 4 with value: 0.08196721311475409.\n",
      "/home/pavithra/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [23:05:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-30 23:06:17,648] Trial 5 finished with value: 0.09210526315789473 and parameters: {'max_depth': 7, 'learning_rate': 0.2115372431144674, 'n_estimators': 83, 'subsample': 0.900164210218797, 'gamma': 0.7545695720990669}. Best is trial 5 with value: 0.09210526315789473.\n",
      "/home/pavithra/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [23:06:18] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-30 23:06:58,424] Trial 6 finished with value: 0.2 and parameters: {'max_depth': 9, 'learning_rate': 0.27575078431012434, 'n_estimators': 69, 'subsample': 0.6785914805836307, 'gamma': 0.5737136862039166}. Best is trial 6 with value: 0.2.\n",
      "/home/pavithra/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [23:06:59] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-30 23:07:47,521] Trial 7 finished with value: 0.08163265306122448 and parameters: {'max_depth': 9, 'learning_rate': 0.20511138172754154, 'n_estimators': 126, 'subsample': 0.8237621646507558, 'gamma': 0.7937376379683504}. Best is trial 6 with value: 0.2.\n",
      "/home/pavithra/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [23:07:48] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-30 23:09:15,235] Trial 8 finished with value: 0.10256410256410256 and parameters: {'max_depth': 9, 'learning_rate': 0.13000364231830658, 'n_estimators': 135, 'subsample': 0.687443953888321, 'gamma': 0.5889065776476015}. Best is trial 6 with value: 0.2.\n",
      "/home/pavithra/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [23:09:15] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-30 23:10:45,222] Trial 9 finished with value: 0.08433734939759036 and parameters: {'max_depth': 5, 'learning_rate': 0.09087718638563051, 'n_estimators': 174, 'subsample': 0.7911783484911195, 'gamma': 0.49114542317780796}. Best is trial 6 with value: 0.2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'max_depth': 9, 'learning_rate': 0.27575078431012434, 'n_estimators': 69, 'subsample': 0.6785914805836307, 'gamma': 0.5737136862039166}\n",
      "Best precision: 0.2\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    # Define hyperparameters to tune\n",
    "    param = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0.0, 1.0),\n",
    "        'scale_pos_weight': 1\n",
    "    }\n",
    "\n",
    "    model = XGBClassifier(**param, use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "\n",
    "    return precision\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "print(f\"Best hyperparameters: {study.best_params}\")\n",
    "print(f\"Best precision: {study.best_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
