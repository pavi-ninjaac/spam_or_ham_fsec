{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-30 23:14:17.145466: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-30 23:14:17.596849: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-30 23:14:17.598774: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-30 23:14:18.628165: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import optuna\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train  (3417, 1000)\n",
      "X test (375, 1000)\n",
      "Y_Train (3417, 1)\n",
      "Y_test (375, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = pd.read_csv(\"/home/pavithra/projects/spam_or_ham_fsec/data/target/X_train.csv\", header=None)\n",
    "X_test = pd.read_csv(\"/home/pavithra/projects/spam_or_ham_fsec/data/target/X_test.csv\", header=None)\n",
    "y_train = pd.read_csv(\"/home/pavithra/projects/spam_or_ham_fsec/data/target/y_train.csv\", header=None)\n",
    "y_test = pd.read_csv(\"/home/pavithra/projects/spam_or_ham_fsec/data/target/y_test.csv\", header=None)\n",
    "\n",
    "\n",
    "\n",
    "print(\"X train \",X_train.shape)\n",
    "print(\"X test\",X_test.shape)\n",
    "print(\"Y_Train\", y_train.shape)\n",
    "print(\"Y_test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(128, activation='relu', input_dim=1000))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               128128    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 136449 (533.00 KB)\n",
      "Trainable params: 136449 (533.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-30 23:14:21,149] A new study created in memory with name: no-name-f0854266-ac31-45f6-a0c8-98e889743c9e\n",
      "/tmp/ipykernel_199153/1146100160.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "[I 2024-11-30 23:14:28,170] Trial 0 finished with value: 11.979991912841797 and parameters: {'layer1_units': 256, 'layer2_units': 32, 'dropout_rate': 0.39682595076410143, 'learning_rate': 0.00010376141143771641, 'batch_size': 16}. Best is trial 0 with value: 11.979991912841797.\n",
      "/tmp/ipykernel_199153/1146100160.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "[I 2024-11-30 23:14:33,522] Trial 1 finished with value: 1354.760498046875 and parameters: {'layer1_units': 160, 'layer2_units': 32, 'dropout_rate': 0.23499776669777628, 'learning_rate': 0.0004690533681180902, 'batch_size': 16}. Best is trial 0 with value: 11.979991912841797.\n",
      "/tmp/ipykernel_199153/1146100160.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "[I 2024-11-30 23:14:35,838] Trial 2 finished with value: 10.369305610656738 and parameters: {'layer1_units': 128, 'layer2_units': 64, 'dropout_rate': 0.44837844870190396, 'learning_rate': 0.0002765026402896292, 'batch_size': 64}. Best is trial 2 with value: 10.369305610656738.\n",
      "/tmp/ipykernel_199153/1146100160.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "[I 2024-11-30 23:14:38,335] Trial 3 finished with value: 2.876979112625122 and parameters: {'layer1_units': 160, 'layer2_units': 128, 'dropout_rate': 0.4973664096493056, 'learning_rate': 0.00010127011818911333, 'batch_size': 64}. Best is trial 3 with value: 2.876979112625122.\n",
      "/tmp/ipykernel_199153/1146100160.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "[I 2024-11-30 23:14:44,367] Trial 4 finished with value: 89.19862365722656 and parameters: {'layer1_units': 192, 'layer2_units': 128, 'dropout_rate': 0.26932266891311896, 'learning_rate': 0.00012475138965873197, 'batch_size': 16}. Best is trial 3 with value: 2.876979112625122.\n",
      "/tmp/ipykernel_199153/1146100160.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "[I 2024-11-30 23:14:50,221] Trial 5 finished with value: 321545.96875 and parameters: {'layer1_units': 192, 'layer2_units': 96, 'dropout_rate': 0.2760559416799991, 'learning_rate': 0.002061653218645262, 'batch_size': 16}. Best is trial 3 with value: 2.876979112625122.\n",
      "/tmp/ipykernel_199153/1146100160.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "[I 2024-11-30 23:14:54,308] Trial 6 finished with value: 1619.3443603515625 and parameters: {'layer1_units': 64, 'layer2_units': 32, 'dropout_rate': 0.41277328835540655, 'learning_rate': 0.0008289018805214852, 'batch_size': 16}. Best is trial 3 with value: 2.876979112625122.\n",
      "/tmp/ipykernel_199153/1146100160.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "[I 2024-11-30 23:14:58,225] Trial 7 finished with value: 137.8077850341797 and parameters: {'layer1_units': 224, 'layer2_units': 96, 'dropout_rate': 0.4957401455252628, 'learning_rate': 0.00028204252348720804, 'batch_size': 32}. Best is trial 3 with value: 2.876979112625122.\n",
      "/tmp/ipykernel_199153/1146100160.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "[I 2024-11-30 23:15:04,418] Trial 8 finished with value: 4083576.25 and parameters: {'layer1_units': 224, 'layer2_units': 64, 'dropout_rate': 0.4877363544234803, 'learning_rate': 0.006070373306998324, 'batch_size': 16}. Best is trial 3 with value: 2.876979112625122.\n",
      "/tmp/ipykernel_199153/1146100160.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "[I 2024-11-30 23:15:07,172] Trial 9 finished with value: 3.2598066329956055 and parameters: {'layer1_units': 224, 'layer2_units': 96, 'dropout_rate': 0.44700881616549976, 'learning_rate': 0.00013718134328201447, 'batch_size': 64}. Best is trial 3 with value: 2.876979112625122.\n",
      "/tmp/ipykernel_199153/1146100160.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "[I 2024-11-30 23:15:09,670] Trial 10 finished with value: 4991.322265625 and parameters: {'layer1_units': 96, 'layer2_units': 128, 'dropout_rate': 0.36142161412499607, 'learning_rate': 0.001845631750930844, 'batch_size': 64}. Best is trial 3 with value: 2.876979112625122.\n",
      "/tmp/ipykernel_199153/1146100160.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "[I 2024-11-30 23:15:12,359] Trial 11 finished with value: 12.878917694091797 and parameters: {'layer1_units': 160, 'layer2_units': 128, 'dropout_rate': 0.44284218506181844, 'learning_rate': 0.0002021284721537661, 'batch_size': 64}. Best is trial 3 with value: 2.876979112625122.\n",
      "/tmp/ipykernel_199153/1146100160.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "[I 2024-11-30 23:15:15,411] Trial 12 finished with value: 2.7465879917144775 and parameters: {'layer1_units': 256, 'layer2_units': 96, 'dropout_rate': 0.33310741978809494, 'learning_rate': 0.00010457514577582886, 'batch_size': 64}. Best is trial 12 with value: 2.7465879917144775.\n",
      "/tmp/ipykernel_199153/1146100160.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "[I 2024-11-30 23:15:17,708] Trial 13 finished with value: 269.99151611328125 and parameters: {'layer1_units': 128, 'layer2_units': 128, 'dropout_rate': 0.30745243175880044, 'learning_rate': 0.0005764889123176331, 'batch_size': 64}. Best is trial 12 with value: 2.7465879917144775.\n",
      "/tmp/ipykernel_199153/1146100160.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "[I 2024-11-30 23:15:21,765] Trial 14 finished with value: 6273164.0 and parameters: {'layer1_units': 256, 'layer2_units': 96, 'dropout_rate': 0.32496866730608165, 'learning_rate': 0.008554564423038192, 'batch_size': 32}. Best is trial 12 with value: 2.7465879917144775.\n",
      "/tmp/ipykernel_199153/1146100160.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "[I 2024-11-30 23:15:24,008] Trial 15 finished with value: 6.54902982711792 and parameters: {'layer1_units': 128, 'layer2_units': 64, 'dropout_rate': 0.36932331868781265, 'learning_rate': 0.00020618501785558163, 'batch_size': 64}. Best is trial 12 with value: 2.7465879917144775.\n",
      "/tmp/ipykernel_199153/1146100160.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "[I 2024-11-30 23:15:26,589] Trial 16 finished with value: 7990.59423828125 and parameters: {'layer1_units': 192, 'layer2_units': 128, 'dropout_rate': 0.2104069672215139, 'learning_rate': 0.001514170672071101, 'batch_size': 64}. Best is trial 12 with value: 2.7465879917144775.\n",
      "/tmp/ipykernel_199153/1146100160.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "[I 2024-11-30 23:15:28,531] Trial 17 finished with value: 56.87202453613281 and parameters: {'layer1_units': 64, 'layer2_units': 96, 'dropout_rate': 0.32421846614416, 'learning_rate': 0.0004830498713939514, 'batch_size': 64}. Best is trial 12 with value: 2.7465879917144775.\n",
      "/tmp/ipykernel_199153/1146100160.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "[I 2024-11-30 23:15:31,367] Trial 18 finished with value: 214241.09375 and parameters: {'layer1_units': 96, 'layer2_units': 128, 'dropout_rate': 0.3938252286238255, 'learning_rate': 0.003367463110054914, 'batch_size': 32}. Best is trial 12 with value: 2.7465879917144775.\n",
      "/tmp/ipykernel_199153/1146100160.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "[I 2024-11-30 23:15:33,924] Trial 19 finished with value: 11.720046043395996 and parameters: {'layer1_units': 160, 'layer2_units': 96, 'dropout_rate': 0.28489474809908855, 'learning_rate': 0.00019557373127473092, 'batch_size': 64}. Best is trial 12 with value: 2.7465879917144775.\n",
      "/tmp/ipykernel_199153/1146100160.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "[I 2024-11-30 23:15:37,056] Trial 20 finished with value: 2.6755287647247314 and parameters: {'layer1_units': 256, 'layer2_units': 64, 'dropout_rate': 0.34634095085644584, 'learning_rate': 0.0001045055576679275, 'batch_size': 64}. Best is trial 20 with value: 2.6755287647247314.\n",
      "/tmp/ipykernel_199153/1146100160.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "[I 2024-11-30 23:15:40,006] Trial 21 finished with value: 2.1616101264953613 and parameters: {'layer1_units': 256, 'layer2_units': 64, 'dropout_rate': 0.33382076889331297, 'learning_rate': 0.00010281328736417759, 'batch_size': 64}. Best is trial 21 with value: 2.1616101264953613.\n",
      "/tmp/ipykernel_199153/1146100160.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "[I 2024-11-30 23:15:42,933] Trial 22 finished with value: 61.37051010131836 and parameters: {'layer1_units': 256, 'layer2_units': 64, 'dropout_rate': 0.3397855687302072, 'learning_rate': 0.00032968346752609173, 'batch_size': 64}. Best is trial 21 with value: 2.1616101264953613.\n",
      "/tmp/ipykernel_199153/1146100160.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "[I 2024-11-30 23:15:45,857] Trial 23 finished with value: 4.523417949676514 and parameters: {'layer1_units': 256, 'layer2_units': 64, 'dropout_rate': 0.30548099552685626, 'learning_rate': 0.00013631580275301366, 'batch_size': 64}. Best is trial 21 with value: 2.1616101264953613.\n",
      "/tmp/ipykernel_199153/1146100160.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "[I 2024-11-30 23:15:48,821] Trial 24 finished with value: 5.243914604187012 and parameters: {'layer1_units': 224, 'layer2_units': 64, 'dropout_rate': 0.3564239818615941, 'learning_rate': 0.00016519352759889185, 'batch_size': 64}. Best is trial 21 with value: 2.1616101264953613.\n",
      "/tmp/ipykernel_199153/1146100160.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "[I 2024-11-30 23:15:53,181] Trial 25 finished with value: 167.4437255859375 and parameters: {'layer1_units': 256, 'layer2_units': 64, 'dropout_rate': 0.38143414864754155, 'learning_rate': 0.00029996965865833916, 'batch_size': 32}. Best is trial 21 with value: 2.1616101264953613.\n",
      "/tmp/ipykernel_199153/1146100160.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "[I 2024-11-30 23:15:55,767] Trial 26 finished with value: 2.2049665451049805 and parameters: {'layer1_units': 224, 'layer2_units': 32, 'dropout_rate': 0.3359576831002062, 'learning_rate': 0.00010192655435213712, 'batch_size': 64}. Best is trial 21 with value: 2.1616101264953613.\n",
      "/tmp/ipykernel_199153/1146100160.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "[I 2024-11-30 23:15:58,376] Trial 27 finished with value: 586.360595703125 and parameters: {'layer1_units': 224, 'layer2_units': 32, 'dropout_rate': 0.24704366014208803, 'learning_rate': 0.0009268388039718897, 'batch_size': 64}. Best is trial 21 with value: 2.1616101264953613.\n",
      "/tmp/ipykernel_199153/1146100160.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "[I 2024-11-30 23:16:01,022] Trial 28 finished with value: 4.726719856262207 and parameters: {'layer1_units': 224, 'layer2_units': 32, 'dropout_rate': 0.3050396891667545, 'learning_rate': 0.0001675739380874217, 'batch_size': 64}. Best is trial 21 with value: 2.1616101264953613.\n",
      "/tmp/ipykernel_199153/1146100160.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "[I 2024-11-30 23:16:04,943] Trial 29 finished with value: 4.084500789642334 and parameters: {'layer1_units': 256, 'layer2_units': 32, 'dropout_rate': 0.4117888699999119, 'learning_rate': 0.00010473949666817377, 'batch_size': 32}. Best is trial 21 with value: 2.1616101264953613.\n",
      "/tmp/ipykernel_199153/1146100160.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "[I 2024-11-30 23:16:07,385] Trial 30 finished with value: 25.520872116088867 and parameters: {'layer1_units': 192, 'layer2_units': 32, 'dropout_rate': 0.3526145784118079, 'learning_rate': 0.00037911419535845603, 'batch_size': 64}. Best is trial 21 with value: 2.1616101264953613.\n",
      "/tmp/ipykernel_199153/1146100160.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "[I 2024-11-30 23:16:10,430] Trial 31 finished with value: 2.720172643661499 and parameters: {'layer1_units': 256, 'layer2_units': 64, 'dropout_rate': 0.33542403978562546, 'learning_rate': 0.00010286891540314104, 'batch_size': 64}. Best is trial 21 with value: 2.1616101264953613.\n",
      "/tmp/ipykernel_199153/1146100160.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "[I 2024-11-30 23:16:13,279] Trial 32 finished with value: 5.214006423950195 and parameters: {'layer1_units': 256, 'layer2_units': 64, 'dropout_rate': 0.37460125240989234, 'learning_rate': 0.00014775511184550916, 'batch_size': 64}. Best is trial 21 with value: 2.1616101264953613.\n",
      "/tmp/ipykernel_199153/1146100160.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "[I 2024-11-30 23:16:16,497] Trial 33 finished with value: 7.8799214363098145 and parameters: {'layer1_units': 256, 'layer2_units': 32, 'dropout_rate': 0.29558993603388606, 'learning_rate': 0.00019994758482752532, 'batch_size': 64}. Best is trial 21 with value: 2.1616101264953613.\n",
      "/tmp/ipykernel_199153/1146100160.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "[I 2024-11-30 23:16:19,441] Trial 34 finished with value: 21.152402877807617 and parameters: {'layer1_units': 224, 'layer2_units': 64, 'dropout_rate': 0.3401162478093582, 'learning_rate': 0.00024549714056359734, 'batch_size': 64}. Best is trial 21 with value: 2.1616101264953613.\n",
      "/tmp/ipykernel_199153/1146100160.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "[I 2024-11-30 23:16:22,486] Trial 35 finished with value: 2.6281797885894775 and parameters: {'layer1_units': 256, 'layer2_units': 64, 'dropout_rate': 0.3278204426206785, 'learning_rate': 0.00010012037661288322, 'batch_size': 64}. Best is trial 21 with value: 2.1616101264953613.\n",
      "/tmp/ipykernel_199153/1146100160.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "[I 2024-11-30 23:16:29,010] Trial 36 finished with value: 20.960472106933594 and parameters: {'layer1_units': 224, 'layer2_units': 32, 'dropout_rate': 0.25862196490349154, 'learning_rate': 0.00012040672358174201, 'batch_size': 16}. Best is trial 21 with value: 2.1616101264953613.\n",
      "/tmp/ipykernel_199153/1146100160.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "[I 2024-11-30 23:16:31,668] Trial 37 finished with value: 4.7593674659729 and parameters: {'layer1_units': 192, 'layer2_units': 64, 'dropout_rate': 0.31665195041860134, 'learning_rate': 0.0001495811956750511, 'batch_size': 64}. Best is trial 21 with value: 2.1616101264953613.\n",
      "/tmp/ipykernel_199153/1146100160.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "[I 2024-11-30 23:16:38,631] Trial 38 finished with value: 4487.39990234375 and parameters: {'layer1_units': 256, 'layer2_units': 32, 'dropout_rate': 0.39363280823068036, 'learning_rate': 0.0006487168797478435, 'batch_size': 16}. Best is trial 21 with value: 2.1616101264953613.\n",
      "/tmp/ipykernel_199153/1146100160.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "[I 2024-11-30 23:16:41,251] Trial 39 finished with value: 15.495068550109863 and parameters: {'layer1_units': 192, 'layer2_units': 64, 'dropout_rate': 0.2809430889640647, 'learning_rate': 0.0002358029548236395, 'batch_size': 64}. Best is trial 21 with value: 2.1616101264953613.\n",
      "/tmp/ipykernel_199153/1146100160.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "[I 2024-11-30 23:16:43,857] Trial 40 finished with value: 76.94580841064453 and parameters: {'layer1_units': 224, 'layer2_units': 64, 'dropout_rate': 0.34959648572020413, 'learning_rate': 0.0004194499413664936, 'batch_size': 64}. Best is trial 21 with value: 2.1616101264953613.\n",
      "/tmp/ipykernel_199153/1146100160.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "[I 2024-11-30 23:16:46,590] Trial 41 finished with value: 2.910933494567871 and parameters: {'layer1_units': 256, 'layer2_units': 64, 'dropout_rate': 0.33939361738754026, 'learning_rate': 0.00010772812771338086, 'batch_size': 64}. Best is trial 21 with value: 2.1616101264953613.\n",
      "/tmp/ipykernel_199153/1146100160.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "[I 2024-11-30 23:16:49,619] Trial 42 finished with value: 2.176321506500244 and parameters: {'layer1_units': 256, 'layer2_units': 64, 'dropout_rate': 0.3194547585415774, 'learning_rate': 0.00010099058853782631, 'batch_size': 64}. Best is trial 21 with value: 2.1616101264953613.\n",
      "/tmp/ipykernel_199153/1146100160.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "[I 2024-11-30 23:16:52,565] Trial 43 finished with value: 3.6242566108703613 and parameters: {'layer1_units': 256, 'layer2_units': 64, 'dropout_rate': 0.3173546902090732, 'learning_rate': 0.0001297815527189998, 'batch_size': 64}. Best is trial 21 with value: 2.1616101264953613.\n",
      "/tmp/ipykernel_199153/1146100160.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "[I 2024-11-30 23:16:59,274] Trial 44 finished with value: 121.40910339355469 and parameters: {'layer1_units': 224, 'layer2_units': 64, 'dropout_rate': 0.2951966703123488, 'learning_rate': 0.0001732105490357885, 'batch_size': 16}. Best is trial 21 with value: 2.1616101264953613.\n",
      "/tmp/ipykernel_199153/1146100160.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "[I 2024-11-30 23:17:02,238] Trial 45 finished with value: 2.938633441925049 and parameters: {'layer1_units': 256, 'layer2_units': 32, 'dropout_rate': 0.2627565913177137, 'learning_rate': 0.00012679003851114197, 'batch_size': 64}. Best is trial 21 with value: 2.1616101264953613.\n",
      "/tmp/ipykernel_199153/1146100160.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "[I 2024-11-30 23:17:05,172] Trial 46 finished with value: 28.564697265625 and parameters: {'layer1_units': 224, 'layer2_units': 96, 'dropout_rate': 0.36476782558720794, 'learning_rate': 0.000245308817770733, 'batch_size': 64}. Best is trial 21 with value: 2.1616101264953613.\n",
      "/tmp/ipykernel_199153/1146100160.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "[I 2024-11-30 23:17:08,179] Trial 47 finished with value: 43685.20703125 and parameters: {'layer1_units': 256, 'layer2_units': 64, 'dropout_rate': 0.383656316722294, 'learning_rate': 0.0033344234199730108, 'batch_size': 64}. Best is trial 21 with value: 2.1616101264953613.\n",
      "/tmp/ipykernel_199153/1146100160.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "[I 2024-11-30 23:17:12,231] Trial 48 finished with value: 14.820226669311523 and parameters: {'layer1_units': 224, 'layer2_units': 96, 'dropout_rate': 0.40802301683380304, 'learning_rate': 0.0001303604361516778, 'batch_size': 32}. Best is trial 21 with value: 2.1616101264953613.\n",
      "/tmp/ipykernel_199153/1146100160.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "[I 2024-11-30 23:17:15,185] Trial 49 finished with value: 2.9581501483917236 and parameters: {'layer1_units': 256, 'layer2_units': 64, 'dropout_rate': 0.3241667597786406, 'learning_rate': 0.00010201055452278027, 'batch_size': 64}. Best is trial 21 with value: 2.1616101264953613.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'layer1_units': 256, 'layer2_units': 64, 'dropout_rate': 0.33382076889331297, 'learning_rate': 0.00010281328736417759, 'batch_size': 64}\n",
      "Best accuracy: 2.1616101264953613\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def create_model(trial):\n",
    "    \"\"\"\n",
    "    Create and return the model I wanna try on.\n",
    "    Which is a nueral network with one hidden layer and a dropout layer.\n",
    "    \"\"\"\n",
    "    # Set the hyperparameters which I wanna try.\n",
    "    layer1_units = trial.suggest_int('layer1_units', 64, 256, step=32)\n",
    "    layer2_units = trial.suggest_int('layer2_units', 32, 128, step=32)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.2, 0.5)\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(layer1_units, activation='relu', input_dim=X_train.shape[1]))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(layer2_units, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def objective(trial):\n",
    "    model = create_model(trial)\n",
    "\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        validation_data=(X_test, y_test),\n",
    "                        epochs=10,\n",
    "                        batch_size=trial.suggest_categorical('batch_size', [16, 32, 64]),\n",
    "                        verbose=0)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    val_loss, val_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    return val_loss\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(f\"Best accuracy: {study.best_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2923225420.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[7], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    Best hyperparameters: {'layer1_units': 128, 'layer2_units': 64, 'dropout_rate': 0.3874414297981386, 'learning_rate': 0.00018557740326790697, 'batch_size': 32}\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Best hyperparameters: {'layer1_units': 128, 'layer2_units': 64, 'dropout_rate': 0.3874414297981386, 'learning_rate': 0.00018557740326790697, 'batch_size': 32}\n",
    "Best accuracy: 13.9380521774292"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'study' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best_trial \u001b[38;5;241m=\u001b[39m \u001b[43mstudy\u001b[49m\u001b[38;5;241m.\u001b[39mbest_params\n\u001b[1;32m      2\u001b[0m final_model \u001b[38;5;241m=\u001b[39m create_model(optuna\u001b[38;5;241m.\u001b[39mtrial\u001b[38;5;241m.\u001b[39mFixedTrial(best_trial))\n\u001b[1;32m      3\u001b[0m final_model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39mbest_trial[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'study' is not defined"
     ]
    }
   ],
   "source": [
    "best_trial = study.best_params\n",
    "final_model = create_model(optuna.trial.FixedTrial(best_trial))\n",
    "final_model.fit(X_train, y_train, epochs=20, batch_size=best_trial['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
